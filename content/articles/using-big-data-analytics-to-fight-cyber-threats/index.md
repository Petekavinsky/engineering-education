Title: Using Big Data analytics to fight cybersecurity threats

Big Data is a term used to describe large amounts of data stored and transmitted in a computer system. Cybersecurity dangers can be combated with the use of big data analytics.

In cybersecurity, big data analytics refers to collecting large amounts of digital data to analyze, display, and draw conclusions that can help forecast and prevent cyber threats.Big data improves our cybersecurity when combined with security technology. For example, it enable businesses to spot behaviour patterns that indicate network vulnerabilities. We look at how Big Data can help improve information security best practices in this article.

Big Data, Cyber Security, Privacy, and Database are just a few terms that come to mind while thinking about this topic.

### Objective
By the end of this tutorial, they should be able to:
- Appreciating the value of Big Data and Cybersecurity
- Recognizing Mega Trends in Technology
- Gain a better understanding of Big Data analytics - Recognize key areas where cybersecurity analytics can help - Use Big Data analytics to combat cyber-threats

### Preliminary
Big Data refers to data sets that are incredibly massive or complicated and for which specific data set processing application software is insufficient or unable to cope. Big data is distinct from typical data in volume, velocity, and variation. Volume denotes the amount of data produced, velocity denotes the rate at which the data is produced, and variation denotes the different types of structured and unstructured data produced.

Big data is a hot topic in practically every industry, particularly cyber security. Social media sites and mobile devices are the primary sources of data generation. The rapid generation of data raises various concerns about the data's security. It is critical to keep this data safe because it contains vital and sensitive information like bank account numbers, passwords, and credit card numbers, among other things. Furthermore, improvements in Big Data analytics have made it easier to extract and use this data, making privacy infractions easier. As a result, in addition to building Big Data technologies, protections to avoid exploitation must also be developed.

There are three ways in which Big Data differs from conventional technology:
- Data volume (Volume) - Dataset size: how much data is generated is a crucial issue.
- The rate at which data is generated and sent (Velocity) - Dataset complexity: the structure, behaviour, and permutations of datasets are essential factors to consider.
- The distinction between organized and unstructured data types (Variety) - Technologies: tools and procedures for processing large or complicated datasets are crucial.

 ### Big Data Mega Trends in Technology
Along with analytics and cloud-based technology, big data is generating a lot of buzz in the business world, the media, and even among consumers. This is part of the contemporary ecosystem that technology megatrends have built.
- Big Data is a broad term that incorporates a variety of trends and new technological advances. Here are the top 10 developing technologies that assist users in dealing with and cost-effectively managing Big Data.
- A database that is based on columns
Traditional, row-oriented databases are great for online transaction processing because of their quick update speeds, but as data volumes expand and data becomes more unstructured, they struggle with query performance.
- Database with no schema or database without SQL
This category includes database types, including key-value storage and document stores, emphasizing storing and retrieving vast amounts of unstructured, semi-structured, and even structured data.
- Reduce - Map
This programming paradigm enables large-scale job execution across thousands of servers or clusters of servers. There are two jobs in every Map Reduce implementation:
   - The "Map" task involves converting an input dataset into a new collection of key/value pairs (tuples). "Reduce" is one of the options.
   - Task, which combines many of the "Map" task's results into a smaller collection of tuples.
   -
Hadoop is the most excellent and widely used version of map-reduce, as it is an entirely open-source platform for managing large amounts of data. In addition, it is adaptable enough to work with a variety of data sets. It has a variety of uses, but one of the most common is for enormous volumes of continuously changing data, such as weather or traffic sensor data.
- Hive: 
- It is a SQL-LIKE bridge that lets you run queries against a Hadoop cluster from a traditional business intelligence application. A higher-level abstraction of the Hadoop framework allows anyone to make queries against data stored in a Hadoop cluster just like they would a conventional data store. It was initially developed by Facebook but has been open source for some time now.
- Wibi  Data: is a hybrid of web analytics and Hadoop, developed on top of Hbase, a Hadoop database layer.
- Sky Tree: 
It is a high-performance machine learning and data analytics platform designed specifically for extensive data processing. Because of the large data, machine learning is a critical component of big data.

### Life cycle of Big Data
 Three stages comprise the big data lifecycle.
- Creation 
- Processing 
- Output

Certain data types cannot be recorded, although they have only been utilized sparingly until now (one general example is the person's location at any particular movement of time, the number of steps a person takes every day).

New and improved technology, such as advanced sensors and bespoke software, can now record and analyze this data type. In addition, changes in communication methods (e.g., social media vs telephone vs text/SMS vs email vs letter) have also improved our capacity to examine topics like customer sentiment.

### Processing
In today's world, we have a massive amount of data that has not been historically recorded and processed for various reasons, the most common of which being that the expense of processing outweighs the value that companies can derive from it. Because processing enormous amounts of data are so costly, a large amount of data is left unprocessed.

However, new technologies have reduced the financial and technological barrier to successful data processing, allowing businesses of all sizes to extract value from various data sources. Unstructured data, for example, is a challenge for traditional relational databases.

Many businesses are looking for a storage solution in the cloud. Cloud computing allows businesses to employ pre-built big data solutions or quickly construct and deploy a powerful array of servers without incurring the high costs of owning physical gear.

### Outputs
Capturing, gathering, storing, and processing data is not straightforward or inexpensive, and it is useless until the data is meaningful; it must also be accessible when needed.
Three major enablers are present:
- Mobile Information may now be distributed in real-time thanks to established mobile networks.
- The ability to review big and complicated data sets has become accessible to the ordinary business user because of visual/interactive technologies.
- Human resources There is a new breed of team members that can handle the complexity of big data and reduce the output for everyday use.

### Big Data analytics in Cybersecurity
The fundamental purpose of using big data in cybersecurity is to use a more sophisticated technique to better identify potential cyber threats. Any system's detection must be swift in order to discover significant and little changes in the system. Analyzing current and historical data from a variety of sources necessitates the use of advanced analytical techniques such as:
1. Fraud detection using Big Data analytics statistical approaches and artificial intelligence are the two main types of fraud detection tools.
The following are some examples of statistical data analysis techniques: 1. Data pre-processing techniques for detecting, validating, correcting errors, and filling in gaps in data.
2. Calculation of numerous statistical parameters such as averages, quintiles, performance metrics, and probability distributions.
3. Business models and probability distributions, either multiple parameters or probability distributions.
4. User profiles are created.
5. Analysis of time-dependent data in time-series format.
6. Clustering and classification to discover patterns and relationships among data sets.
7. Anomalies in transaction or user behaviour relative to previously known models and profiles are detected using matching algorithms. Techniques to eliminate false alerts, quantify risks, and anticipate the future of existing transactions or users are also required. Fraud management requires a great deal of knowledge.

The main AI techniques used for fraud management include [AI]:
1. Use data mining to classify automatically, cluster, and segment data and uncover relationships and rules that may indicate exciting trends, such as fraud tendencies.
2. Expert systems that encode knowledge in the form of rules for identifying fraud.
3. Pattern recognition to find approximations of classes, clusters, or patterns of suspicious behaviour either automatically (unsupervised) or by matching given inputs.
4. Automated fraud detection using machine learning approaches.
5. Neural networks can learn suspicious patterns from samples and then utilize them to detect them in the future.

### Anomaly Detection with Big Data
Intrusion detection systems are a collection of techniques for monitoring and analyzing events in a computer or network for evidence of malicious activity. Illegitimate monitoring, unauthorized access to remote or local resources, and denial of service are examples of unwelcome actions.

Anomaly detection algorithms are relatively easy to set up and operate independently. Some key performance indicators are selected for each event, and thresholds established. The occurrence is flagged for further examination when a certain threshold is reached. The choice of indicators to be monitored, the analysis time, and the threshold value choices all impact the success of this strategy.

### Increasing Big Data Security to prevent cyber threats
When cyberthieves target Big Data sets, the payoff is frequently well worth the effort required to breach security layers, which is why big data is a fantastic potential for businesses and cybercriminals. When they go after such a massive data set, they have more to gain. As a result, businesses stand to lose a lot more if they are subjected to a cyber attack without adequate security measures.

### Considerations for extensive data security
1. Collaborating with peers in the sector to develop industry standards, avoid government requirements, and share best practices
2. To safeguard sensitive information supplied by third parties, attribute-based encryption is used.
3. Hadoop, for example, is secure open-source software.
4. Keep and monitor audit logs for all aspects of the firm.
Overall, big data has significant opportunities for enterprises that extend far beyond improved business intelligence.
 Big data has the potential to improve cyber security. However, to capitalize on the numerous opportunities presented by big data, businesses must accept the duty and risk of data protection.
 
### Challenges of Big Data analytics
1. Not all businesses are data-driven. They are unsure about big data analytics and may not grasp the benefits of analytics.
2. Big data analytics may be viewed as a means of extracting value from data by organizations. However, it is more about identifying the most appropriate use case for the targeted business goal.
3. From scope design to data extraction and delivery, the analytics team and users collaborate during all steps of the analytics process.
4. Because it is difficult to grasp how data might yield such outcomes, management may be unable to trust the analytics results.
5. There is a scarcity of data scientists that are well-educated and experienced.
### Conclusion
Big Data analytics for security aims to provide real-time intelligence. In three ways, Big Data can significantly impact your present business. First, it may be helpful in the following situations:
1. Look for undiscovered information When evaluating a high service cancellation rate, for example, customer survey data may reveal a trend or previously undetectable core reason, which may be eliminated to increase retention.
2. Help decision-makers make better decisions by providing more information. Consider a customer's social media profile, for example, and you can obtain a better image of that customer and their place in the world, which you may use to improve your response to service inquiries or prioritize fraud warnings.
3. Business procedures should be automated. For example, you can analyze extensive stock trading data to spot trends that lead to sloppy trade execution and automate the process to implement particular actions when the pattern arises again.
